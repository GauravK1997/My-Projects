{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "extended-drinking",
   "metadata": {},
   "source": [
    "# Stepwise Procedure :\n",
    "\n",
    "1) Importing required Libraries\n",
    "\n",
    "2) Specifying paths for respective directories\n",
    "\n",
    "3) Data Augmentation\n",
    "\n",
    "4) Generating the augmented images with batch sizes in specified directories\n",
    "\n",
    "5) Building the model architecture\n",
    "\n",
    "6) Compiling the model\n",
    "\n",
    "7) Fitting the model to train it\n",
    "\n",
    "8) Saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-worth",
   "metadata": {},
   "source": [
    "# A) Binary Classification :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "decent-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Importing required Libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Specifying paths for respective directories\n",
    "\n",
    "train_dir = ''\n",
    "val_dir = ''\n",
    "test_dir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Data Augmentation\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  rotation_range=40,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Generating the augmented images with batch sizes in specified directories\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(150,150),\n",
    "                                                    batch_size=20,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
    "                                                        target_size=(150,150),\n",
    "                                                        batch_size=20,\n",
    "                                                        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "suited-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Building the model architecture\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Dropout((0.4)),\n",
    "    \n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Dropout((0.4)),\n",
    "    \n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Dropout((0.4)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dropout((0.5)),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Compiling the model\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-pioneer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Fitting the model to train it\n",
    "# Specify the Generators(train_generator & validation_generator) here\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                             steps_per_epoch=100,\n",
    "                             epochs=100,\n",
    "                             validation_data=validation_generator,\n",
    "                             validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Saving the model\n",
    "\n",
    "model.save('model_name.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-shock",
   "metadata": {},
   "source": [
    "# B) Multi Class Classification :\n",
    "\n",
    "Differences : (3 Differences)\n",
    "\n",
    "1) 4th step : Generating the augmented images\n",
    "                class_mode='categorical'\n",
    "\n",
    "2) 5th step : Building the model architecture\n",
    "                last Dense layer : Dense(5, activation='softmax')\n",
    "                No. of neurons = No. of Output Classes\n",
    "                \n",
    "3) 6th step : Compiling the model\n",
    "                loss='categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Importing required Libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Specifying paths for respective directories\n",
    "\n",
    "train_dir = ''\n",
    "val_dir = ''\n",
    "test_dir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Data Augmentation\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  rotation_range=40,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Generating the augmented images with batch sizes in specified directories\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(150,150),\n",
    "                                                    batch_size=20,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
    "                                                        target_size=(150,150),\n",
    "                                                        batch_size=20,\n",
    "                                                        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-devil",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Building the model architecture\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Dropout((0.4)),\n",
    "    \n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Dropout((0.4)),\n",
    "    \n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Dropout((0.4)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dropout((0.5)),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(5, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Compiling the model\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Fitting the model to train it\n",
    "# Specify the Generators(train_generator & validation_generator) here\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                             steps_per_epoch=100,\n",
    "                             epochs=100,\n",
    "                             validation_data=validation_generator,\n",
    "                             validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Saving the model\n",
    "\n",
    "model.save('model_name.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-chassis",
   "metadata": {},
   "source": [
    "# Transfer Learning : (Pre trained Convolutional Base)\n",
    "\n",
    "Additional steps :\n",
    "\n",
    "1) Import the required library of the Pre-trained model and\n",
    "\n",
    "2) Save the top layers(conv layers) of this model in a variable and later use this as the conv base of our model\n",
    "\n",
    "3) Change the layers.trainable = False :\n",
    "        \n",
    "        Coz if we train the conv layers of pre-trained model, its previous training will be of no use\n",
    "\n",
    "4) 5th step : (Building the model architecture)\n",
    "        \n",
    "        Build the model with conv base of this pre-trained model and add this to Classifier(Dense layers) which we will \n",
    "        build according to our need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "controlled-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Importing required Libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Specific Library for the pre-trained model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adult-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional step : Importing the top of the pre-trained model(the convolutional base)\n",
    "\n",
    "conv_base = VGG16(include_top=False, input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "south-finding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are not training the conv layers of the model, coz it doesn't make any sense to train them here\n",
    "\n",
    "for layer in conv_base.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-appearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Specifying paths for respective directories\n",
    "\n",
    "train_dir = ''\n",
    "val_dir = ''\n",
    "test_dir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Data Augmentation\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  rotation_range=40,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-welding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Generating the augmented images with batch sizes in specified directories\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(150,150),\n",
    "                                                    batch_size=20,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
    "                                                        target_size=(150,150),\n",
    "                                                        batch_size=20,\n",
    "                                                        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Building the model architecture\n",
    "\n",
    "model = models.Sequential([\n",
    "                           conv_base,\n",
    "    \n",
    "                           layers.Flatten(),\n",
    "    \n",
    "                           layers.Dropout((0.5)),\n",
    "                           layers.Dense(512, activation='relu'),\n",
    "                           layers.BatchNormalization(),\n",
    "    \n",
    "                           layers.Dense(256, activation='relu'),\n",
    "                           layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Compiling the model\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Fitting the model to train it\n",
    "# Specify the Generators(train_generator & validation_generator) here\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                             steps_per_epoch=100,\n",
    "                             epochs=100,\n",
    "                             validation_data=validation_generator,\n",
    "                             validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Saving the model\n",
    "\n",
    "model.save('model_name.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
